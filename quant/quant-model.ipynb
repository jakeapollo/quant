{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from typing import List, Tuple, Iterable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleTaskDataset(Dataset[tuple[torch.Tensor, torch.Tensor]]):\n",
    "    # create a dataset of sequences of length `n_control_bits` + `n_task_bits`\n",
    "    # the sequences are bit strings. The first `n_control_bits` bits describe the task: \n",
    "    # they are zero everywhere except for the `task_num`-th bit, which is 1.\n",
    "    # The next `n_task_bits` bits are random.\n",
    "    # The target is the parity of the relevant variables, which are at the indices of the task bits\n",
    "    # given in `relevant_vars`.\n",
    "        def __init__(self,\n",
    "                     n_task_bits: int,\n",
    "                     n_control_bits: int,\n",
    "                     task_num: int,\n",
    "                     relevant_vars: torch.Tensor,\n",
    "                     dataset_length: int):\n",
    "\n",
    "            assert len(relevant_vars.shape) == 1\n",
    "            assert relevant_vars.dtype == torch.int64\n",
    "            assert relevant_vars.shape[0] <= n_task_bits\n",
    "            assert all([0 <= i < n_task_bits for i in relevant_vars])\n",
    "            self.data = torch.zeros(dataset_length, n_control_bits + n_task_bits)\n",
    "            self.task_bits = torch.randint(0, 2, (dataset_length, n_task_bits), dtype=torch.float32)\n",
    "            self.data[:, n_control_bits + 1:] = self.task_bits\n",
    "            self.data[:, task_num] = 1.\n",
    "            self.dataset_length = dataset_length\n",
    "            \n",
    "            self.relevant_vars = relevant_vars\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.dataset_length\n",
    "\n",
    "        def __getitem__(self, idx: int | slice):\n",
    "            x = self.data[idx]\n",
    "            y = self.task_bits[idx, self.relevant_vars].sum() % 2\n",
    "            return x, y\n",
    "\n",
    "class MultiTaskDataset(Dataset[tuple[torch.Tensor, torch.Tensor]]):\n",
    "    def __init__(self,\n",
    "                 n_task_bits: int,\n",
    "                 n_control_bits: int,\n",
    "                 relevant_vars: List[torch.Tensor],\n",
    "                 dataset_length_per_task: int | list[int]):\n",
    "        if isinstance(dataset_length_per_task, list):\n",
    "            assert len(dataset_length_per_task) == n_control_bits\n",
    "            data_set_lengths = dataset_length_per_task\n",
    "        else:\n",
    "            data_set_lengths = [dataset_length_per_task] * n_control_bits\n",
    "        \n",
    "        self.datasets = [SingleTaskDataset(n_task_bits, n_control_bits, i, relevant_vars[i], data_set_lengths[i]) for i in range(len(relevant_vars))]\n",
    "        \n",
    "        self.datasets = [SingleTaskDataset(n_task_bits, n_control_bits, i, relevant_vars[i], dataset_length) for i in range(len(relevant_vars))]\n",
    "        self.dataset_length = dataset_length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
